{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8pUq/ZzqwHx5a5dZ6/CBz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathjams/AAAI_2024/blob/main/Region_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting which of $k^2$ regions the hand fixation lies in"
      ],
      "metadata": {
        "id": "ZrJl2kP2prGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Labeling hand fixation coordinates with its region in the $k\\times k$ grid."
      ],
      "metadata": {
        "id": "8Yg_9Cpyp5w-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each output has one of $k^2$ labels."
      ],
      "metadata": {
        "id": "nCBd8HQzqKs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math as math\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "def discretesequences2(user_type,k):\n",
        "  resulteye=[]\n",
        "  resulthand=[]\n",
        "  maxlen=0\n",
        "  maxlenh = 0\n",
        "  eye_basic_url='/Users/qyuvks/emily/AAAI/data_set/Eye_'\n",
        "  hand_basic_url='/Users/qyuvks/emily/AAAI/data_set/Hand_'\n",
        "  if (user_type=='ASD'):\n",
        "    numOfUser=9\n",
        "    eye_basic_url+=\"ASD_\"\n",
        "    hand_basic_url+='ASD_'\n",
        "  else:\n",
        "    eye_basic_url+=\"TD_\"\n",
        "    hand_basic_url+='TD_'\n",
        "    numOfUser=17\n",
        "  for i in range(1, numOfUser+1):\n",
        "    for j in range(0,2):\n",
        "      c_eye_url=eye_basic_url+'U'+str(i)+\"_Active_\"+str(j)+\".xlsx\"\n",
        "      c_hand_url=hand_basic_url+'U'+str(i)+\"_Active_\"+str(j)+\".xlsx\"\n",
        "      #asd_eye_data=pd.DataFrame()\n",
        "      try:\n",
        "        asd_eye_data=pd.read_excel(c_eye_url)\n",
        "        asd_hand_data=pd.read_excel(c_hand_url)\n",
        "        starttime= min(np.min(asd_hand_data['start']), np.min(asd_eye_data['start']))\n",
        "        asd_eye_data['start']+=-starttime\n",
        "        asd_eye_data['end']+=-starttime\n",
        "        resulteye.append(asd_eye_data[['x','y','start', 'end']].to_numpy())\n",
        "        asdhandx=asd_hand_data['x']\n",
        "        asdhandy=asd_hand_data['y']\n",
        "        regions = [0]*len(asdhandx)\n",
        "        for i in range(len(asdhandx)):\n",
        "          regions[i]=math.floor(k*asdhandx[i])+math.floor(k*asdhandy[i])*k+1\n",
        "        resulthand.append(regions)\n",
        "        c_max_length=max(asd_eye_data.shape[0], asd_hand_data.shape[0])\n",
        "        if c_max_length>maxlen:\n",
        "          maxlen=c_max_length\n",
        "        if len(regions)>maxlenh:\n",
        "          maxlenh = len(regions)\n",
        "      except IOError:\n",
        "        print(\"\")\n",
        "  resulthand2 = pad_sequences(resulthand, maxlen=maxlenh, padding='post', dtype='int32', value=0)\n",
        "  resulthand3 = np.array(resulthand2)\n",
        "  return resulteye, resulthand3, maxlen, maxlenh"
      ],
      "metadata": {
        "id": "-v1KlVDpp07G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM Model Used"
      ],
      "metadata": {
        "id": "4t0lMQunqHSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "def LSTM_model(input_data, output_data, input_max_len, output_max_len, input_features, output_classes, latent_dim, number_of_epochs):\n",
        "    # Pad the input sequences to their respective maximum lengths\n",
        "    input_data_padded = pad_sequences(input_data, maxlen=input_max_len, padding='post', dtype='float32', value=0)\n",
        "    # Convert output data to one-hot encoding if it is not already\n",
        "    output_data_one_hot = np.eye(output_classes)[output_data]\n",
        "\n",
        "    if len(output_data_one_hot.shape) == 2:\n",
        "        output_data_one_hot = np.expand_dims(output_data_one_hot, axis=-1)\n",
        "        print(len(output_data_one_hot.shape))\n",
        "\n",
        "    # Pad the output sequences\n",
        "    output_data_padded = pad_sequences(output_data_one_hot, maxlen=output_max_len, padding='post', dtype='float32', value=0)\n",
        "\n",
        "    # Shift the output sequences to create the target sequences\n",
        "    decoder_target_data = np.roll(output_data_padded, shift=-1, axis=1)\n",
        "    decoder_target_data[:, -1, :] = 0  # Reset last time step to 0 (zero padding)\n",
        "\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(None, input_features), name='encoder_inputs')\n",
        "    encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_LSTM')\n",
        "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(None, output_classes), name='decoder_inputs')\n",
        "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_LSTM')\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "    decoder_dense = TimeDistributed(Dense(output_classes, activation='softmax'))\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Define the model that will turn encoder_inputs and decoder_inputs into decoder_outputs\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Fit the model\n",
        "#    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
        "#    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    result = model.fit([input_data_padded, output_data_padded], decoder_target_data,\n",
        "                      batch_size=50, epochs=number_of_epochs, validation_split=0.2)\n",
        "\n",
        "    final_loss = result.history['val_loss'][-1]\n",
        "    print(f'Final validation loss: {final_loss}')\n",
        "\n",
        "    # Define the encoder model (used for encoding input sequences to their states)\n",
        "    encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    # Define the decoder model (used for generating output sequences given the encoded states)\n",
        "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h_dec, state_c_dec]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "\n",
        "    # Extract the number of epochs\n",
        "    epochs = range(1, number_of_epochs + 1)\n",
        "    val_loss = result.history['val_loss']\n",
        "    val_accuracy = result.history['val_accuracy']\n",
        "    # Save the models\n",
        "    return model, encoder_model, decoder_model, val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "yhZ65xlPqITZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistical Tests"
      ],
      "metadata": {
        "id": "LgKLh4SuqdVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "import scipy.stats as stats\n",
        "Statistics = []\n",
        "testing = [10,20,50,100]\n",
        "for j in range(4):\n",
        "    asdfit=[]\n",
        "    tdfit=[]\n",
        "    i=testing[j]\n",
        "    asdresulteye, asdresulthand, asdmaxlen, asdmaxlenh=discretesequences2('ASD', i)\n",
        "    tdresulteye, tdresulthand, tdmaxlen, tdmaxlenh=discretesequences2('TD', i)\n",
        "    for j in range(5):\n",
        "        modelasd, encoder_modelasd, decoder_modelasd, val_lossasd, val_accuracyasd = LSTM_model(asdresulteye, asdresulthand, asdmaxlen, asdmaxlenh, 4, i**2, 150, 1000)\n",
        "        modeltd, encoder_modeltd, decoder_modeltd, val_losstd, val_accuracytd = LSTM_model(tdresulteye, tdresulthand, tdmaxlen, tdmaxlenh, 4, i**2, 150, 1000)\n",
        "        asdfit.append(min(val_lossasd))\n",
        "        tdfit.append(min(val_losstd))\n",
        "    t_statistic, p_value = stats.ttest_ind(asdfit, tdfit)\n",
        "    meanASD = statistics.mean(asdfit)\n",
        "    meanTD = statistics.mean(tdfit)\n",
        "    std_asd = statistics.pstdev(asdfit)\n",
        "    std_td = statistics.pstdev(tdfit)\n",
        "    print([i, t_statistic, p_value, meanASD, meanTD, std_asd, std_td])\n",
        "    Statistics.append([i, t_statistic, p_value, meanASD, meanTD, std_asd, std_td])\n",
        "print(Statistics)"
      ],
      "metadata": {
        "id": "7ulfu6LWqc9x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}