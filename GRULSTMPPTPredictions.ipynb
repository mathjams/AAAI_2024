{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNI2mdHVi7cGFuvg293CIPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathjams/AAAI_2024/blob/main/GRULSTMPPTPredictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU/LSTM P/PT Predictions\n"
      ],
      "metadata": {
        "id": "Yi83fqzS87wo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuwW1GMw8wo7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Embedding, Concatenate\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Input, GRU, Dense, TimeDistributed, Embedding, Concatenate\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import scipy.stats as stats\n",
        "import statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation\n"
      ],
      "metadata": {
        "id": "P2-Em4nV8-SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plainsequences(user_type):\n",
        "  resulteye=[]\n",
        "  resulthand=[]\n",
        "  maxlen=0\n",
        "  eye_basic_url='/Users/qyuvks/emily/AAAI/data_set/Eye_'\n",
        "  hand_basic_url='/Users/qyuvks/emily/AAAI/data_set/Hand_'\n",
        "  if (user_type=='ASD'):\n",
        "    numOfUser=9\n",
        "    eye_basic_url+=\"ASD_\"\n",
        "    hand_basic_url+='ASD_'\n",
        "  else:\n",
        "    eye_basic_url+=\"TD_\"\n",
        "    hand_basic_url+='TD_'\n",
        "    numOfUser=17\n",
        "  for i in range(1, numOfUser+1):\n",
        "    for j in range(0,2):\n",
        "      c_eye_url=eye_basic_url+'U'+str(i)+\"_Active_\"+str(j)+\".xlsx\"\n",
        "      c_hand_url=hand_basic_url+'U'+str(i)+\"_Active_\"+str(j)+\".xlsx\"\n",
        "      try:\n",
        "        asd_eye_data=pd.read_excel(c_eye_url)\n",
        "        asd_hand_data=pd.read_excel(c_hand_url)\n",
        "        resulteye.append(asd_eye_data[['x','y']].to_numpy())\n",
        "        resulthand.append(asd_hand_data[['x','y']].to_numpy())\n",
        "        c_max_length=max(asd_eye_data.shape[0], asd_hand_data.shape[0])\n",
        "        if c_max_length>maxlen:\n",
        "          maxlen=c_max_length\n",
        "      except IOError:\n",
        "        print(\"\")\n",
        "  return resulteye, resulthand, maxlen"
      ],
      "metadata": {
        "id": "gvJDxYZu897z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data for Position and Time as input\n",
        "\n"
      ],
      "metadata": {
        "id": "LdscRB9I9AbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plainsequences2(user_type):\n",
        "  resulteye=[]\n",
        "  resulthand=[]\n",
        "  maxlen=0\n",
        "  eye_basic_url='/Users/qyuvks/emily/AAAI/data_set/Eye_'\n",
        "  hand_basic_url='/Users/qyuvks/emily/AAAI/data_set/Hand_'\n",
        "  if (user_type=='ASD'):\n",
        "    numOfUser=9\n",
        "    eye_basic_url+=\"ASD_\"\n",
        "    hand_basic_url+='ASD_'\n",
        "  else:\n",
        "    eye_basic_url+=\"TD_\"\n",
        "    hand_basic_url+='TD_'\n",
        "    numOfUser=17\n",
        "  for i in range(1, numOfUser+1):\n",
        "    for j in range(0,2):\n",
        "      c_eye_url=eye_basic_url+'U'+str(i)+\"_Active_\"+str(j)+\".xlsx\"\n",
        "      c_hand_url=hand_basic_url+'U'+str(i)+\"_Active_\"+str(j)+\".xlsx\"\n",
        "      #asd_eye_data=pd.DataFrame()\n",
        "      try:\n",
        "        asd_eye_data=pd.read_excel(c_eye_url)\n",
        "        asd_hand_data=pd.read_excel(c_hand_url)\n",
        "        starttime= min(np.min(asd_hand_data['start']), np.min(asd_eye_data['start']))\n",
        "        asd_eye_data['start']+=-starttime\n",
        "        asd_eye_data['end']+=-starttime\n",
        "        asd_hand_data['start']+=-starttime\n",
        "        asd_hand_data['end']+=-starttime\n",
        "        resulteye.append(asd_eye_data[['x','y','start', 'end']].to_numpy())\n",
        "        resulthand.append(asd_hand_data[['x','y']].to_numpy())\n",
        "        c_max_length=max(asd_eye_data.shape[0], asd_hand_data.shape[0])\n",
        "        if c_max_length>maxlen:\n",
        "          maxlen=c_max_length\n",
        "      except IOError:\n",
        "        print(\"\")\n",
        "  return resulteye, resulthand, maxlen"
      ],
      "metadata": {
        "id": "70WB_Cy39F1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM and GRU Models\n"
      ],
      "metadata": {
        "id": "zqA2o5bg9H7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def masked_mse_loss(y_true, y_pred):\n",
        "    # Create a mask to ignore the padded values (assumes padding is done with 0s)\n",
        "    mask = tf.cast(tf.not_equal(y_true, 0), dtype=tf.float32)\n",
        "    # Compute MSE and apply the mask\n",
        "    mse = tf.square(y_true - y_pred) * mask\n",
        "    # Take the mean of the MSE, dividing by the non-zero entries in the mask\n",
        "    return tf.reduce_sum(mse) / tf.reduce_sum(mask)\n",
        "\n",
        "def plot_loss(history):\n",
        "    # Plot the training and validation loss over epochs\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history['loss'], label='Training Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def LSTM_model4(input_data, output_data, input_max_len, output_max_len, input_features, output_features, latent_dim, number_of_epochs):\n",
        "    # Pad the input and output sequences to their respective maximum lengths\n",
        "    input_data_padded = pad_sequences(input_data, maxlen=input_max_len, padding='post', dtype='float32', value=0)\n",
        "    output_data_padded = pad_sequences(output_data, maxlen=output_max_len, padding='post', dtype='float32', value=0)\n",
        "\n",
        "    # Shift the output sequences to create the target sequences\n",
        "    decoder_target_data = np.roll(output_data_padded, shift=-1, axis=1)\n",
        "    decoder_target_data[:, -1, :] = 0  # Reset last time step to 0 (zero padding)\n",
        "\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(None, input_features), name='encoder_inputs')\n",
        "    encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_LSTM')\n",
        "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(None, output_features), name='decoder_inputs')\n",
        "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_LSTM')\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "    decoder_dense = TimeDistributed(Dense(output_features, activation='linear'))\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Define the model that will turn encoder_inputs and decoder_inputs into decoder_outputs\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss=masked_mse_loss)\n",
        "\n",
        "    # Fit the model\n",
        "    result = model.fit(\n",
        "        [input_data_padded, output_data_padded],\n",
        "        decoder_target_data,\n",
        "        batch_size=50,\n",
        "        epochs=number_of_epochs,\n",
        "        validation_split=0.2,\n",
        "        verbose=1  # Set verbose=1 to print loss at each epoch\n",
        "    )\n",
        "\n",
        "    # Extract the validation loss from the history\n",
        "    val_loss = result.history['val_loss']\n",
        "    loss = result.history['loss']\n",
        "\n",
        "    # Print the minimum validation loss\n",
        "    min_val_loss = min(val_loss)\n",
        "    print(f'Minimum validation loss: {min_val_loss}')\n",
        "\n",
        "    # Plot the training and validation loss\n",
        "    plot_loss(result.history)\n",
        "\n",
        "    # Define the encoder model (used for encoding input sequences to their states)\n",
        "    encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    # Define the decoder model (used for generating output sequences given the encoded states)\n",
        "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h_dec, state_c_dec]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "\n",
        "    # Return model and training history\n",
        "    return min_val_loss\n",
        "\n",
        "def GRU_model4(input_data, output_data, input_max_len, output_max_len, input_features, output_features, latent_dim, number_of_epochs):\n",
        "    # Pad the input and output sequences to their respective maximum lengths\n",
        "    input_data_padded = pad_sequences(input_data, maxlen=input_max_len, padding='post', dtype='float32', value=0)\n",
        "    output_data_padded = pad_sequences(output_data, maxlen=output_max_len, padding='post', dtype='float32', value=0)\n",
        "\n",
        "    # Shift the output sequences to create the target sequences\n",
        "    decoder_target_data = np.roll(output_data_padded, shift=-1, axis=1)\n",
        "    decoder_target_data[:, -1, :] = 0  # Reset last time step to 0 (zero padding)\n",
        "\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(None, input_features), name='encoder_inputs')\n",
        "    encoder_gru = GRU(latent_dim, return_state=True, name='encoder_GRU')\n",
        "    encoder_outputs, state_h = encoder_gru(encoder_inputs)\n",
        "    encoder_states = [state_h]  # GRU only has a single hidden state\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(None, output_features), name='decoder_inputs')\n",
        "    decoder_gru = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder_GRU')\n",
        "    decoder_outputs, _ = decoder_gru(decoder_inputs, initial_state=encoder_states)\n",
        "    decoder_dense = TimeDistributed(Dense(output_features, activation='linear'))\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Define the model that will turn encoder_inputs and decoder_inputs into decoder_outputs\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss=masked_mse_loss)\n",
        "\n",
        "    # Fit the model\n",
        "    result = model.fit(\n",
        "        [input_data_padded, output_data_padded],\n",
        "        decoder_target_data,\n",
        "        batch_size=50,\n",
        "        epochs=number_of_epochs,\n",
        "        validation_split=0.2,\n",
        "        verbose=1  # Set verbose=1 to print loss at each epoch\n",
        "    )\n",
        "\n",
        "    # Extract the validation loss from the history\n",
        "    val_loss = result.history['val_loss']\n",
        "    loss = result.history['loss']\n",
        "\n",
        "    # Print the minimum validation loss\n",
        "    min_val_loss = min(val_loss)\n",
        "    print(f'Minimum validation loss: {min_val_loss}')\n",
        "\n",
        "    # Plot the training and validation loss\n",
        "    plot_loss(result.history)\n",
        "\n",
        "    # Define the encoder model (used for encoding input sequences to their states)\n",
        "    encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    # Define the decoder model (used for generating output sequences given the encoded states)\n",
        "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "    decoder_states_inputs = [decoder_state_input_h]\n",
        "\n",
        "    decoder_outputs, state_h_dec = decoder_gru(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h_dec]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "\n",
        "    # Return model and training history\n",
        "    return min_val_loss"
      ],
      "metadata": {
        "id": "-OdxCYdu9wXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical Tests and Comparison of Models\n"
      ],
      "metadata": {
        "id": "xe1cJMI1-Ihi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "asdresulteye, asdresulthand = plainsequences('ASD')\n",
        "tdresulteye, tdresulthand = plainsequences('TD')\n",
        "asdresulteye2, asdresulthand2 =  plainsequences2('ASD')\n",
        "tdresulteye2, tdresulthand2 =  plainsequences2('TD')"
      ],
      "metadata": {
        "id": "mUQ9XADC-QMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#experiment on Active\n",
        "import statistics\n",
        "import scipy.stats as stats\n",
        "\n",
        "asdgrufit2=[]\n",
        "asdgrufit4=[]\n",
        "asdlstmfit2 = []\n",
        "asdlstmfit4 = []\n",
        "tdlstmfit2=[]\n",
        "tdlstmfit4=[]\n",
        "tdgrufit2=[]\n",
        "tdgrufit4=[]\n",
        "for i in range(3):\n",
        "    lval_losstd2 = LSTM_model4(tdresulteye, tdresulthand, 236, 236, 2, 2, 64, 1000)\n",
        "    gval_losstd2 = GRU_model4(tdresulteye, tdresulthand, 236, 236, 2, 2, 64, 1000)\n",
        "    tdlstmfit2.append(lval_losstd2)\n",
        "    tdgrufit2.append(gval_losstd2)\n",
        "    lval_losstd4 = LSTM_model4(tdresulteye2, tdresulthand2, 236, 236, 4, 2, 64, 1000)\n",
        "    gval_losstd4 = GRU_model4(tdresulteye2, tdresulthand2, 236, 236, 4, 2, 64, 1000)\n",
        "    tdlstmfit4.append(lval_losstd4)\n",
        "    tdgrufit4.append(gval_losstd4)\n",
        "    lval_lossasd2 = LSTM_model4(asdresulteye, asdresulthand, 260, 260, 2, 2, 64, 1000)\n",
        "    gval_lossasd2 = GRU_model4(asdresulteye, asdresulthand, 260, 260, 2, 2, 64, 1000)\n",
        "    asdlstmfit2.append(lval_lossasd2)\n",
        "    asdgrufit2.append(gval_lossasd2)\n",
        "    lval_lossasd4 = LSTM_model4(asdresulteye2, asdresulthand2, 260, 260, 4, 2, 64, 1000)\n",
        "    gval_lossasd4 = GRU_model4(asdresulteye2, asdresulthand2, 260, 260, 4, 2, 64, 1000)\n",
        "    asdlstmfit4.append(lval_lossasd4)\n",
        "    asdgrufit4.append(gval_lossasd4)\n",
        "print(asdlstmfit2)\n",
        "print(asdlstmfit4)\n",
        "print(asdgrufit2)\n",
        "print(asdgrufit4)\n",
        "print(tdlstmfit2)\n",
        "print(tdlstmfit4)\n",
        "print(tdgrufit2)\n",
        "print(tdgrufit4)"
      ],
      "metadata": {
        "id": "YzWvkd8Y-Ka0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#experimental Results\n",
        "print(statistics.mean(asdlstmfit2), statistics.mean(asdlstmfit4), statistics.mean(asdgrufit2), statistics.mean(asdgrufit4), statistics.mean(tdlstmfit2), statistics.mean(tdlstmfit4), statistics.mean(tdgrufit2), statistics.mean(tdgrufit4))\n",
        "#compare within groups for ASD\n",
        "asd2t_statistic, asd2p_value = stats.ttest_ind(asdlstmfit2, asdgrufit2)\n",
        "print(f\"The comparison between GRU and LSTM for ASD with 2 features is {asd2t_statistic} and {asd2p_value}\")\n",
        "asd4t_statistic, asd4p_value = stats.ttest_ind(asdlstmfit4, asdgrufit4)\n",
        "print(f\"The comparison between GRU and LSTM for ASD with 4 features is {asd4t_statistic} and {asd4p_value}\")\n",
        "l24asdt_statistic, l24asdp_value = stats.ttest_ind(asdlstmfit2, asdlstmfit4)\n",
        "print(f\"The comparison between 2 and 4 features in ASD with LSTM is {l24asdt_statistic} and {l24asdp_value}\")\n",
        "g24asdt_statistic, g24asdp_value = stats.ttest_ind(asdgrufit2, asdgrufit4)\n",
        "print(f\"The comparison between 2 and 4 features in ASD with GRU is {g24asdt_statistic} and {g24asdp_value}\")\n",
        "#compare within groups for TD\n",
        "td2t_statistic, td2p_value = stats.ttest_ind(tdlstmfit2, tdgrufit2)\n",
        "print(f\"The comparison between GRU and LSTM for TD with 2 features is {td2t_statistic} and {td2p_value}\")\n",
        "td4t_statistic, td4p_value = stats.ttest_ind(tdlstmfit4, tdgrufit4)\n",
        "print(f\"The comparison between GRU and LSTM for TD with 4 features is {td4t_statistic} and {td4p_value}\")\n",
        "l24tdt_statistic, l24tdp_value = stats.ttest_ind(tdlstmfit2, tdlstmfit4)\n",
        "print(f\"The comparison between 2 and 4 features in TD with LSTM is {l24tdt_statistic} and {l24tdp_value}\")\n",
        "g24tdt_statistic, g24tdp_value = stats.ttest_ind(tdgrufit2, tdgrufit4)\n",
        "print(f\"The comparison between 2 and 4 features in TD with GRU is {g24tdt_statistic} and {g24tdp_value}\")\n",
        "#between group comparsion\n",
        "l2t_statistic, l2p_value = stats.ttest_ind(asdlstmfit2, tdlstmfit2)\n",
        "print(f\"The comparison between ASD and TD for LSTM with 2 features is {l2t_statistic} and {l2p_value}\")\n",
        "g2t_statistic, g2p_value = stats.ttest_ind(asdgrufit2, tdgrufit2)\n",
        "print(f\"The comparison between ASD and TD for GRU with 2 features is {g2t_statistic} and {g2p_value}\")\n",
        "l4t_statistic, l4p_value = stats.ttest_ind(asdlstmfit4, tdlstmfit4)\n",
        "print(f\"The comparison between ASD and TD for LSTM with 4 features is {l4t_statistic} and {l4p_value}\")\n",
        "g4t_statistic, g4p_value = stats.ttest_ind(asdgrufit4, tdgrufit4)\n",
        "print(f\"The comparison between ASD and TD for GRU with 4 features is {g4t_statistic} and {g4p_value}\")"
      ],
      "metadata": {
        "id": "GuBi3BH3-Q7h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}