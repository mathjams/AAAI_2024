{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyONcleyel4At2/raH54oleH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathjams/AAAI_2024/blob/main/GRU_LSTM_P_PT_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU/LSTM P/PT Predictions\n"
      ],
      "metadata": {
        "id": "RY2lu7G3oDV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, Embedding, Concatenate\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Input, GRU, Dense, TimeDistributed, Embedding, Concatenate\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import scipy.stats as stats\n",
        "import statistics"
      ],
      "metadata": {
        "id": "U1D9vcf-oJn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "UyN3Q7faodnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data for Position as input"
      ],
      "metadata": {
        "id": "jLQiQfG-oOYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plainsequences(user_type):\n",
        "  resulteye=[]\n",
        "  resulthand=[]\n",
        "  maxlen=0\n",
        "  eye_basic_url='/Users/qyuvks/emily/AAAI/data_set/Eye_'\n",
        "  hand_basic_url='/Users/qyuvks/emily/AAAI/data_set/Hand_'\n",
        "  if (user_type=='ASD'):\n",
        "    numOfUser=9\n",
        "    eye_basic_url+=\"ASD_\"\n",
        "    hand_basic_url+='ASD_'\n",
        "  else:\n",
        "    eye_basic_url+=\"TD_\"\n",
        "    hand_basic_url+='TD_'\n",
        "    numOfUser=17\n",
        "  for i in range(1, numOfUser+1):\n",
        "    for j in range(0,2):\n",
        "      c_eye_url=eye_basic_url+'U'+str(i)+\"_Active_\"+str(j)+\".xlsx\"\n",
        "      c_hand_url=hand_basic_url+'U'+str(i)+\"_Active_\"+str(j)+\".xlsx\"\n",
        "      try:\n",
        "        asd_eye_data=pd.read_excel(c_eye_url)\n",
        "        asd_hand_data=pd.read_excel(c_hand_url)\n",
        "        resulteye.append(asd_eye_data[['x','y']].to_numpy())\n",
        "        resulthand.append(asd_hand_data[['x','y']].to_numpy())\n",
        "        c_max_length=max(asd_eye_data.shape[0], asd_hand_data.shape[0])\n",
        "        if c_max_length>maxlen:\n",
        "          maxlen=c_max_length\n",
        "      except IOError:\n",
        "        print(\"\")\n",
        "  return resulteye, resulthand, maxlen"
      ],
      "metadata": {
        "id": "nMH_LFlHoKIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data for Position and Time as input"
      ],
      "metadata": {
        "id": "XhgFBEZBoSaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plainsequences2(user_type):\n",
        "  resulteye=[]\n",
        "  resulthand=[]\n",
        "  maxlen=0\n",
        "  eye_basic_url='/Users/qyuvks/emily/AAAI/data_set/Eye_'\n",
        "  hand_basic_url='/Users/qyuvks/emily/AAAI/data_set/Hand_'\n",
        "  if (user_type=='ASD'):\n",
        "    numOfUser=9\n",
        "    eye_basic_url+=\"ASD_\"\n",
        "    hand_basic_url+='ASD_'\n",
        "  else:\n",
        "    eye_basic_url+=\"TD_\"\n",
        "    hand_basic_url+='TD_'\n",
        "    numOfUser=17\n",
        "  for i in range(1, numOfUser+1):\n",
        "    for j in range(0,2):\n",
        "      c_eye_url=eye_basic_url+'U'+str(i)+\"_Active_\"+str(j)+\".xlsx\"\n",
        "      c_hand_url=hand_basic_url+'U'+str(i)+\"_Active_\"+str(j)+\".xlsx\"\n",
        "      #asd_eye_data=pd.DataFrame()\n",
        "      try:\n",
        "        asd_eye_data=pd.read_excel(c_eye_url)\n",
        "        asd_hand_data=pd.read_excel(c_hand_url)\n",
        "        starttime= min(np.min(asd_hand_data['start']), np.min(asd_eye_data['start']))\n",
        "        asd_eye_data['start']+=-starttime\n",
        "        asd_eye_data['end']+=-starttime\n",
        "        asd_hand_data['start']+=-starttime\n",
        "        asd_hand_data['end']+=-starttime\n",
        "        resulteye.append(asd_eye_data[['x','y','start', 'end']].to_numpy())\n",
        "        resulthand.append(asd_hand_data[['x','y']].to_numpy())\n",
        "        c_max_length=max(asd_eye_data.shape[0], asd_hand_data.shape[0])\n",
        "        if c_max_length>maxlen:\n",
        "          maxlen=c_max_length\n",
        "      except IOError:\n",
        "        print(\"\")\n",
        "  return resulteye, resulthand, maxlen"
      ],
      "metadata": {
        "id": "7BjLJVHGoMVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM and GRU Models"
      ],
      "metadata": {
        "id": "p1sps4Tdob0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_model4(input_data, output_data, input_max_len, output_max_len, input_features, output_features, latent_dim, number_of_epochs):\n",
        "    # Pad the input and output sequences to their respective maximum lengths\n",
        "    input_data_padded = pad_sequences(input_data, maxlen=input_max_len, padding='post', dtype='float32', value=0)\n",
        "    output_data_padded = pad_sequences(output_data, maxlen=output_max_len, padding='post', dtype='float32', value=0)\n",
        "\n",
        "    # Shift the output sequences to create the target sequences\n",
        "    decoder_target_data = np.roll(output_data_padded, shift=-1, axis=1)\n",
        "    decoder_target_data[:, -1, :] = 0  # Reset last time step to 0 (zero padding)\n",
        "\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(None, input_features), name='encoder_inputs')\n",
        "    encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_LSTM')\n",
        "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(None, output_features), name='decoder_inputs')\n",
        "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_LSTM')\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "    decoder_dense = TimeDistributed(Dense(output_features, activation='linear'))\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Define the model that will turn encoder_inputs and decoder_inputs into decoder_outputs\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
        "\n",
        "    # Fit the model\n",
        "    result = model.fit([input_data_padded, output_data_padded], decoder_target_data,\n",
        "                       batch_size=50, epochs=number_of_epochs, validation_split=0.2)\n",
        "\n",
        "    final_loss = result.history['val_loss'][-1]\n",
        "    print(f'Final validation loss: {final_loss}')\n",
        "\n",
        "    # Define the encoder model (used for encoding input sequences to their states)\n",
        "    encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    # Define the decoder model (used for generating output sequences given the encoded states)\n",
        "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h_dec, state_c_dec]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "  # Extract the number of epochs\n",
        "    epochs = range(1, number_of_epochs + 1)\n",
        "\n",
        "# Extract the validation loss from the history\n",
        "    val_loss = result.history['val_loss']\n",
        "    return model, encoder_model, decoder_model, val_loss"
      ],
      "metadata": {
        "id": "8tWg-RRooZMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "\n",
        "def GRU_model4(input_data, output_data, input_max_len, output_max_len, input_features, output_features, latent_dim, number_of_epochs):\n",
        "    # Pad the input and output sequences to their respective maximum lengths\n",
        "    input_data_padded = pad_sequences(input_data, maxlen=input_max_len, padding='post', dtype='float32', value=0)\n",
        "    output_data_padded = pad_sequences(output_data, maxlen=output_max_len, padding='post', dtype='float32', value=0)\n",
        "\n",
        "    # Shift the output sequences to create the target sequences\n",
        "    decoder_target_data = np.roll(output_data_padded, shift=-1, axis=1)\n",
        "    decoder_target_data[:, -1, :] = 0  # Reset last time step to 0 (zero padding)\n",
        "\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(None, input_features), name='encoder_inputs')\n",
        "    encoder_gru = GRU(latent_dim, return_state=True, name='encoder_GRU')\n",
        "    encoder_outputs, state_h = encoder_gru(encoder_inputs)\n",
        "    encoder_states = [state_h]\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(None, output_features), name='decoder_inputs')\n",
        "    decoder_gru = GRU(latent_dim, return_sequences=True, return_state=True, name='decoder_GRU')\n",
        "    decoder_outputs, state_h_dec = decoder_gru(decoder_inputs, initial_state=encoder_states)\n",
        "    decoder_dense = TimeDistributed(Dense(output_features, activation='linear'))\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Define the model that will turn encoder_inputs and decoder_inputs into decoder_outputs\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
        "\n",
        "    # Fit the model\n",
        "    result = model.fit([input_data_padded, output_data_padded], decoder_target_data,\n",
        "                       batch_size=50, epochs=number_of_epochs, validation_split=0.2)\n",
        "\n",
        "    final_loss = result.history['val_loss'][-1]\n",
        "    print(f'Final validation loss: {final_loss}')\n",
        "\n",
        "    # Define the encoder model (used for encoding input sequences to their states)\n",
        "    encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    # Define the decoder model (used for generating output sequences given the encoded states)\n",
        "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "    decoder_states_inputs = [decoder_state_input_h]\n",
        "\n",
        "    decoder_outputs, state_h_dec = decoder_gru(\n",
        "        decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + [state_h_dec])\n",
        "\n",
        "    # Extract the number of epochs\n",
        "    epochs = range(1, number_of_epochs + 1)\n",
        "\n",
        "    # Extract the validation loss from the history\n",
        "    val_loss = result.history['val_loss']\n",
        "    return model, encoder_model, decoder_model, val_loss"
      ],
      "metadata": {
        "id": "9YyXLl0nosYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistical Tests and Comparison of Models"
      ],
      "metadata": {
        "id": "iQogaC4uotEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "import scipy.stats as stats\n",
        "\n",
        "asdlstmfit2=[]\n",
        "asdlstmfit4=[]\n",
        "asdgrufit2=[]\n",
        "asdgrufit4=[]\n",
        "tdlstmfit2=[]\n",
        "tdlstmfit4=[]\n",
        "tdgrufit2=[]\n",
        "tdgrufit4=[]\n",
        "for i in range(5):\n",
        "    lmodeltd2, lencoder_modeltd2, ldecoder_modeltd2, lval_losstd2 = LSTM_model4(tdresulteye, tdresulthand, tdmaxlen, tdmaxlen, 2, 2, 150, 1000)\n",
        "    gmodeltd2, gencoder_modeltd2, gdecoder_modeltd2, gval_losstd2 = GRU_model4(tdresulteye, tdresulthand, tdmaxlen, tdmaxlen, 2, 2, 150, 1000)\n",
        "    tdlstmfit2.append(min(lval_losstd2))\n",
        "    tdgrufit2.append(min(gval_losstd2))\n",
        "    lmodeltd4, lencoder_modeltd4, ldecoder_modeltd4, lval_losstd4 = LSTM_model4(tdresulteye2, tdresulthand2, tdmaxlen, tdmaxlen, 4, 2, 150, 1000)\n",
        "    gmodeltd4, gencoder_modeltd4, gdecoder_modeltd4, gval_losstd4 = GRU_model4(tdresulteye2, tdresulthand2, tdmaxlen, tdmaxlen, 4, 2, 150, 1000)\n",
        "    tdlstmfit4.append(min(lval_losstd4))\n",
        "    tdgrufit4.append(min(gval_losstd4))\n",
        "    lmodelasd2, lencoder_modelasd2, ldecoder_modelasd2, lval_lossasd2 = LSTM_model4(asdresulteye, asdresulthand, asdmaxlen, asdmaxlen, 2, 2, 150, 1000)\n",
        "    gmodelasd2, gencoder_modelasd2, gdecoder_modelasd2, gval_lossasd2 = GRU_model4(asdresulteye, asdresulthand, asdmaxlen, asdmaxlen, 2, 2, 150, 1000)\n",
        "    asdlstmfit2.append(min(lval_lossasd2))\n",
        "    asdgrufit2.append(min(gval_lossasd2))\n",
        "    lmodelasd4, lencoder_modelasd4, ldecoder_modelasd4, lval_lossasd4 = LSTM_model4(asdresulteye2, asdresulthand2, asdmaxlen, asdmaxlen, 4, 2, 150, 1000)\n",
        "    gmodelasd4, gencoder_modelasd4, gdecoder_modelasd4, gval_lossasd4 = GRU_model4(asdresulteye2, asdresulthand2, asdmaxlen, asdmaxlen, 4, 2, 150, 1000)\n",
        "    asdlstmfit4.append(min(lval_lossasd4))\n",
        "    asdgrufit4.append(min(gval_lossasd4))\n",
        "print(asdlstmfit2)\n",
        "print(asdlstmfit4)\n",
        "print(asdgrufit2)\n",
        "print(asdgrufit4)\n",
        "print(tdlstmfit2)\n",
        "print(tdlstmfit4)\n",
        "print(tdgrufit2)\n",
        "print(tdgrufit4)\n",
        "print(statistics.mean(asdlstmfit2), statistics.mean(asdlstmfit4), statistics.mean(asdgrufit2), statistics.mean(asdgrufit4), statistics.mean(tdlstmfit2), statistics.mean(tdlstmfit4), statistics.mean(tdgrufit2), statistics.mean(tdgrufit4))\n",
        "#compare within groups for ASD\n",
        "asd2t_statistic, asd2p_value = stats.ttest_ind(asdlstmfit2, asdgrufit2)\n",
        "print(f\"The comparison between GRU and LSTM for ASD with 2 features is {asd2t_statistic} and {asd2p_value}\")\n",
        "asd4t_statistic, asd4p_value = stats.ttest_ind(asdlstmfit4, asdgrufit4)\n",
        "print(f\"The comparison between GRU and LSTM for ASD with 4 features is {asd4t_statistic} and {asd4p_value}\")\n",
        "l24asdt_statistic, l24asdp_value = stats.ttest_ind(asdlstmfit2, asdlstmfit4)\n",
        "print(f\"The comparison between 2 and 4 features in ASD with LSTM is {l24asdt_statistic} and {l24asdp_value}\")\n",
        "g24asdt_statistic, g24asdp_value = stats.ttest_ind(asdgrufit2, asdgrufit4)\n",
        "print(f\"The comparison between 2 and 4 features in ASD with GRU is {g24asdt_statistic} and {g24asdp_value}\")\n",
        "#compare within groups for TD\n",
        "td2t_statistic, td2p_value = stats.ttest_ind(tdlstmfit2, tdgrufit2)\n",
        "print(f\"The comparison between GRU and LSTM for TD with 2 features is {td2t_statistic} and {td2p_value}\")\n",
        "td4t_statistic, td4p_value = stats.ttest_ind(tdlstmfit4, tdgrufit4)\n",
        "print(f\"The comparison between GRU and LSTM for TD with 4 features is {td4t_statistic} and {td4p_value}\")\n",
        "l24tdt_statistic, l24tdp_value = stats.ttest_ind(tdlstmfit2, tdlstmfit4)\n",
        "print(f\"The comparison between 2 and 4 features in TD with LSTM is {l24tdt_statistic} and {l24tdp_value}\")\n",
        "g24tdt_statistic, g24tdp_value = stats.ttest_ind(tdgrufit2, tdgrufit4)\n",
        "print(f\"The comparison between 2 and 4 features in TD with GRU is {g24tdt_statistic} and {g24tdp_value}\")\n",
        "#between group comparsion\n",
        "l2t_statistic, l2p_value = stats.ttest_ind(asdlstmfit2, tdlstmfit2)\n",
        "print(f\"The comparison between ASD and TD for LSTM with 2 features is {l2t_statistic} and {l2p_value}\")\n",
        "g2t_statistic, g2p_value = stats.ttest_ind(asdgrufit2, tdgrufit2)\n",
        "print(f\"The comparison between ASD and TD for LSTM with 2 features is {g2t_statistic} and {g2p_value}\")\n",
        "l4t_statistic, l4p_value = stats.ttest_ind(asdlstmfit4, tdlstmfit4)\n",
        "print(f\"The comparison between ASD and TD for LSTM with 4 features is {l4t_statistic} and {l4p_value}\")\n",
        "g4t_statistic, g4p_value = stats.ttest_ind(asdgrufit4, tdgrufit4)\n",
        "print(f\"The comparison between ASD and TD for LSTM with 2 features is {g4t_statistic} and {g4p_value}\")"
      ],
      "metadata": {
        "id": "7ReKEuEzonRk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
